<!doctype html>
<html lang="pt-BR">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Câmera + Detecção de Faces (sem identificação)</title>
<style>
  body{font-family:Inter,system-ui,Arial;display:flex;flex-direction:column;align-items:center;gap:12px;padding:18px}
  #video{width:720px;max-width:95%;border-radius:8px;box-shadow:0 6px 18px rgba(0,0,0,.12)}
  #canvas{position:absolute;pointer-events:none}
  .wrap{position:relative;display:inline-block}
  .controls{display:flex;gap:8px;flex-wrap:wrap;justify-content:center}
  button,select{padding:8px 12px;border-radius:8px;border:1px solid #ddd;background:#fff;cursor:pointer}
  #info{margin-top:8px}
</style>
</head>
<body>
  <h2>Câmera + Detecção de Faces (sem identificação)</h2>

  <div class="wrap">
    <video id="video" autoplay playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <div class="controls">
    <button id="start">Iniciar câmera</button>
    <button id="capture">Tirar foto</button>
    <button id="downloadBoxes">Baixar crop das faces (ZIP)</button>
    <select id="devices"></select>
    <label>
      <input type="checkbox" id="autoDetect" checked /> Detecção automática
    </label>
  </div>

  <div id="info">Faces detectadas: <span id="faceCount">0</span></div>

  <!-- face-api.js (modelo rodando no browser) -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <script>
  // elementos
  const video = document.getElementById('video');
  const overlay = document.getElementById('overlay');
  const startBtn = document.getElementById('start');
  const captureBtn = document.getElementById('capture');
  const devicesSelect = document.getElementById('devices');
  const faceCountEl = document.getElementById('faceCount');
  const autoDetectCheckbox = document.getElementById('autoDetect');
  const downloadBoxesBtn = document.getElementById('downloadBoxes');

  let stream = null;
  let detectionInterval = null;
  let detections = [];

  async function listDevices() {
    const devices = await navigator.mediaDevices.enumerateDevices();
    devicesSelect.innerHTML = '';
    devices.filter(d => d.kind === 'videoinput').forEach((d, i) => {
      const opt = document.createElement('option');
      opt.value = d.deviceId;
      opt.text = d.label || `Câmera ${i+1}`;
      devicesSelect.appendChild(opt);
    });
  }

  async function startCamera(deviceId) {
    stopStream();
    const constraints = {
      audio: false,
      video: {
        deviceId: deviceId ? { exact: deviceId } : undefined,
        width: { ideal: 1280 },
        height: { ideal: 720 }
      }
    };
    stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
    await video.play();
    // ajustar canvas overlay ao tamanho do vídeo
    overlay.width = video.videoWidth;
    overlay.height = video.videoHeight;
  }

  function stopStream() {
    if (!stream) return;
    stream.getTracks().forEach(t => t.stop());
    stream = null;
    video.srcObject = null;
    clearInterval(detectionInterval);
  }

  // carrega os modelos do face-api (faz isso uma vez)
  async function loadModels() {
    // você pode hospedar os modelos localmente; aqui usamos CDN
    const MODEL_URL = 'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights';
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
      faceapi.nets.faceLandmark68TinyNet.loadFromUri(MODEL_URL) // opcional: landmarks
    ]);
    console.log('Modelos carregados');
  }

  // detecta faces e desenha caixas
  async function detectAndDraw() {
    if (!video || video.readyState !== 4) return;
    const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 416, scoreThreshold: 0.5 });
    const results = await faceapi.detectAllFaces(video, options).withFaceLandmarks(true);
    detections = results; // salvar no escopo
    drawDetections(results);
    faceCountEl.textContent = results.length;
  }

  function drawDetections(results) {
    const ctx = overlay.getContext('2d');
    overlay.width = video.videoWidth;
    overlay.height = video.videoHeight;
    ctx.clearRect(0,0,overlay.width,overlay.height);

    ctx.lineWidth = 2;
    ctx.font = '16px Inter, Arial';
    ctx.textBaseline = 'top';

    results.forEach((res, i) => {
      const box = res.detection.box;
      ctx.strokeStyle = 'lime';
      ctx.strokeRect(box.x, box.y, box.width, box.height);

      // desenhar landmarks (olhos, nariz, boca) - opcional
      if (res.landmarks) {
        ctx.fillStyle = 'rgba(255,255,255,0.8)';
        res.landmarks.positions.slice(0,10).forEach(p => {
          ctx.fillRect(p.x-1, p.y-1, 2, 2);
        });
      }

      ctx.fillStyle = 'rgba(0,0,0,0.5)';
      ctx.fillRect(box.x, box.y - 20, 80, 20);
      ctx.fillStyle = '#fff';
      ctx.fillText(`face ${i+1}`, box.x + 6, box.y - 18);
    });
  }

  // tira foto e baixa
  function captureAndDownload() {
    if (!video) return;
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    const dataUrl = canvas.toDataURL('image/png');

    const a = document.createElement('a');
    a.href = dataUrl;
    a.download = `foto_${Date.now()}.png`;
    a.click();
  }

  // opcional: extrair crops das faces e baixar como imagens individuais
  async function downloadFaceCrops() {
    if (!detections || !detections.length) return alert('Nenhuma face detectada');
    // cria zip com JSZip (se quiser) — aqui vamos baixar várias imagens sequenciais
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // para cada face recorta e baixa
    detections.forEach((d, idx) => {
      const box = d.detection.box;
      const c = document.createElement('canvas');
      c.width = Math.round(box.width);
      c.height = Math.round(box.height);
      const cctx = c.getContext('2d');
      cctx.drawImage(canvas, box.x, box.y, box.width, box.height, 0, 0, c.width, c.height);
      const url = c.toDataURL('image/png');
      const a = document.createElement('a');
      a.href = url;
      a.download = `face_${idx+1}_${Date.now()}.png`;
      a.click();
    });
  }

  // eventos
  startBtn.addEventListener('click', async () => {
    try {
      await startCamera(devicesSelect.value || undefined);
      if (autoDetectCheckbox.checked) {
        clearInterval(detectionInterval);
        detectionInterval = setInterval(detectAndDraw, 300); // a cada 300ms
      }
    } catch (err) {
      console.error(err);
      alert('Erro ao acessar câmera: ' + err.message);
    }
  });

  captureBtn.addEventListener('click', captureAndDownload);
  downloadBoxesBtn.addEventListener('click', downloadFaceCrops);

  devicesSelect.addEventListener('change', async () => {
    await startCamera(devicesSelect.value);
  });

  autoDetectCheckbox.addEventListener('change', () => {
    clearInterval(detectionInterval);
    if (autoDetectCheckbox.checked) detectionInterval = setInterval(detectAndDraw, 300);
  });

  // init
  (async () => {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      alert('Seu navegador não suporta getUserMedia.');
      return;
    }
    await listDevices();
    await loadModels(); // carrega os modelos
    // não inicia a câmera automaticamente por melhores práticas de UX
  })();

  </script>
</body>
</html>
